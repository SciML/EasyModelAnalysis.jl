var documenterSearchIndex = {"docs":
[{"location":"api/sensitivity_analysis/#Sensitivity-Analysis","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"","category":"section"},{"location":"api/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"get_sensitivity\ncreate_sensitivity_plot","category":"page"},{"location":"api/sensitivity_analysis/#EasyModelAnalysis.get_sensitivity","page":"Sensitivity Analysis","title":"EasyModelAnalysis.get_sensitivity","text":"get_sensitivity(prob, t, x, pbounds)\n\nReturns the Sobol Indices that quantify the uncertainty of the solution at time t and observation x to the parameters in pbounds.\n\nArguments\n\nt: The time of observation, the solution is stored at this time to obtain the relevant observed variable.\nx: The observation symbolic expression or a function that acts on the solution object.\npbounds: An array with the bounds for each parameter, passed as a pair of parameter expression and a vector with the upper and lower bound.\n\nKeyword Arguments\n\nsamples: Number of samples for running the global sensitivity analysis.\n\nReturns\n\nA dictionary with the first, second and total order indices for all parameters (and pairs in case of second order).\n\n\n\n\n\n","category":"function"},{"location":"api/sensitivity_analysis/#EasyModelAnalysis.create_sensitivity_plot","page":"Sensitivity Analysis","title":"EasyModelAnalysis.create_sensitivity_plot","text":"create_sensitivity_plot(prob, t, x, pbounds)\n\nCreates bar plots of the first, second and total order Sobol indices that quantify sensitivity of the solution at time t and state x to the parameters in pbounds.\n\nSee also get_sensitivity\n\n\n\n\n\ncreate_sensitivity_plot(sensres, pbounds, total_only = false; kw...)\n\nCreates bar plots of the first, second and total order Sobol indices from the result of get_sensitivity and pbounds.\n\nSee also get_sensitivity\n\n\n\n\n\n","category":"function"},{"location":"scenarios/scenario2/#Scenario-2:-Limiting-Hospitalizations","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"","category":"section"},{"location":"scenarios/scenario2/#Generate-the-Model-and-Dataset","page":"Scenario 2: Limiting Hospitalizations","title":"Generate the Model and Dataset","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"using EasyModelAnalysis, Optimization, OptimizationMOI, NLopt, Plots, Random\nRandom.seed!(12345)\n\n@variables t\nDₜ = Differential(t)\n@variables S(t)=0.97 E(t)=0.02 I(t)=0.01 R(t)=0.0 H(t)=0.0 D(t)=0.0\n@variables T(t)=10000.0 η(t)=0.0 cumulative_I(t)=0.0\n@parameters β₁=0.06 β₂=0.015 β₃=0.005 α=0.003 γ₁=0.007 γ₂=0.001 δ=0.2 μ=0.04\neqs = [T ~ S + E + I + R + H + D\n    η ~ (β₁ * E + β₂ * I + β₃ * H)\n    Dₜ(S) ~ -η * S\n    Dₜ(E) ~ η * S - α * E\n    Dₜ(I) ~ α * E - (γ₁ + δ) * I\n    Dₜ(cumulative_I) ~ I\n    Dₜ(R) ~ γ₁ * I + γ₂ * H\n    Dₜ(H) ~ δ * I - (μ + γ₂) * H\n    Dₜ(D) ~ μ * H];\n@named seirhd = ODESystem(eqs)\nseirhd = structural_simplify(seirhd)\nprob = ODEProblem(seirhd, [], (0.0, 60.0), saveat = 1.0)\nsol = solve(prob)\nu60 = sol[:, end]\nplot(sol)","category":"page"},{"location":"scenarios/scenario2/#Model-Analysis","page":"Scenario 2: Limiting Hospitalizations","title":"Model Analysis","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Parameterize model either using data from the previous two months (October 28th – December 28th, 2021), or with relevant parameter values from the literature.","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"data = [I => sol[I], R => sol[R], H => sol[H], D => sol[D]]\nprior_mean = [0.06, 0.015, 0.005, 0.003, 0.007, 0.001, 0.2, 0.04]\nprior_sd = [0.006, 0.0015, 0.0005, 0.0003, 0.0007, 0.0001, 0.02, 0.004]\np = [β₁, β₂, β₃, α, γ₁, γ₂, δ, μ]\np_priors = Pair.(p,\n    Truncated.(Normal.(prior_mean, prior_sd), prior_mean - 3 * prior_sd,\n        prior_mean + 3 * prior_sd))\ntsave = collect(0.0:1.0:60.0)\nfit = bayesian_datafit(prob, p_priors, tsave, data, noise_prior = InverseGamma(10, 0.1))","category":"page"},{"location":"scenarios/scenario2/#Question-1","page":"Scenario 2: Limiting Hospitalizations","title":"Question 1","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Forecast Covid cases and hospitalizations over the next 3 months under no interventions.","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"prob = remake(prob; u0 = u60,\n    p = Pair.(getfield.(fit, :first), mean.(getfield.(fit, :second))))\nforecast_threemonths = solve(prob, tspan = (0.0, 90.0), saveat = 1.0)\nplot(forecast_threemonths)","category":"page"},{"location":"scenarios/scenario2/#Question-2","page":"Scenario 2: Limiting Hospitalizations","title":"Question 2","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Based on the forecast, do we need interventions to keep total Covid hospitalizations under a threshold of 3000 on any given day? If there is uncertainty in the model parameters, express the answer probabilistically, i.e., what is the likelihood or probability that the number of Covid hospitalizations will stay under this threshold for the next 3 months without interventions?","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"need_intervention = maximum(forecast_threemonths[H]) > 0.05","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"post_mean = mean.(getfield.(fit, :second))\npost_sd = sqrt.(var.(getfield.(fit, :second)))\ntrunc_min = post_mean .- 3 * post_sd\ntrunc_max = post_mean .+ 3 * post_sd\npost_trunc = Truncated.(Normal.(post_mean, post_sd), trunc_min, trunc_max)\nposterior = Pair.(getfield.(fit, :first), post_trunc)\nprob_violating_threshold(prob, posterior, [H > 0.05])","category":"page"},{"location":"scenarios/scenario2/#Question-3","page":"Scenario 2: Limiting Hospitalizations","title":"Question 3","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Assume a consistent policy of social distancing/masking will be implemented, resulting in a 50% decrease from baseline transmission. Assume that we want to minimize the time that the policy is in place, and once it has been put in place and then ended, it can't be re-implemented. Looking forward from “today’s” date of Dec. 28, 2021, what are the optimal start and end dates for this policy, to keep projections below the hospitalization threshold over the entire 3-month period? How many fewer hospitalizations and cases does this policy result in?","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"function f(ts, p = nothing)\n    tstart = ts[1]\n    tstop = ts[2]\n    tstop - tstart\nend\n\nfunction g(res, ts, p = nothing)\n    tstart = ts[1]\n    tstop = ts[2]\n    start_intervention = (t == tstart) => [β₁ ~ β₁ / 2, β₂ ~ β₂ / 2, β₃ ~ β₃ / 2]\n    stop_intervention = (t == tstop) => [β₁ ~ β₁ * 2, β₂ ~ β₂ * 2, β₃ ~ β₃ * 2]\n    @named opttime_sys = ODESystem(eqs, t;\n        discrete_events = [\n            start_intervention,\n            stop_intervention,\n        ])\n    opttime_sys = structural_simplify(opttime_sys)\n    prob = ODEProblem(opttime_sys, [], [0.0, 90.0])\n    prob = remake(prob; u0 = u60)\n    sol = solve(prob, saveat = 0.0:1.0:90.0, tstops = [tstart, tstop])\n    hospitalizations = sol(0.0:1.0:90.0, idxs = H)\n    if SciMLBase.successful_retcode(sol.retcode)\n        res .= vcat(hospitalizations, tstop - tstart)\n    else\n        res .= Inf\n    end\nend\n\noptf = OptimizationFunction(f, Optimization.AutoFiniteDiff(), cons = g)\noptprob = Optimization.OptimizationProblem(optf, [0.0, 90.0], lb = [0.0, 0.0],\n    ub = [90.0, 90.0],\n    lcons = vcat(fill(-Inf, 91), 0.0),\n    ucons = vcat(fill(0.05, 91), Inf))\nmin_intervention_timespan = solve(optprob,\n    OptimizationMOI.MOI.OptimizerWithAttributes(NLopt.Optimizer,\n        \"algorithm\" => :GN_ORIG_DIRECT,\n        \"maxtime\" => 60.0))\nmin_intervention_timespan.u","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"res = zeros(92)\ng(res, min_intervention_timespan.u)\nmaximum(res[1:91])","category":"page"},{"location":"scenarios/scenario2/#Question-4","page":"Scenario 2: Limiting Hospitalizations","title":"Question 4","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Assume there is a protocol to kick in mitigation policies when hospitalizations rise above 80% of the hospitalization threshold (i.e. 80% of 3000). When hospitalizations fall back below 80% of the threshold, these policies expire.","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"When do we expect these policies to first kick in?","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"What is the minimum impact on transmission rate these mitigation policies need to have the first time they kick in, to (1) ensure that we don't reach the hospitalization threshold at any time during the 3-month period, and (2) ensure that the policies only need to be implemented once, and potentially expired later, but never reimplemented? Express this in terms of change in baseline transmission levels (e.g. 10% decrease, 50% decrease, etc.).","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"function f(reduction_rate, p = nothing)\n    reduction_rate = reduction_rate[1]\nend\nfunction g(res, reduction_rate, p = nothing)\n    reduction_rate = reduction_rate[1]\n    root_eqs = [H ~ 0.05 * 0.8]\n    affect = [\n        β₁ ~ β₁ * (1 - reduction_rate),\n        β₂ ~ β₂ * (1 - reduction_rate),\n        β₃ ~ β₃ * (1 - reduction_rate),\n    ]\n    @named mask_system = ODESystem(eqs, t; continuous_events = root_eqs => affect)\n    mask_system = structural_simplify(mask_system)\n    prob = ODEProblem(mask_system, [], (0.0, 90.0))\n    prob = remake(prob; u0 = u60)\n    sol = solve(prob, saveat = 0.0:1.0:90.0)\n    hospitalizations = sol(0.0:1.0:90.0, idxs = H)\n    if SciMLBase.successful_retcode(sol.retcode)\n        res .= hospitalizations\n    else\n        res .= Inf\n    end\nend\noptf = OptimizationFunction(f, Optimization.AutoFiniteDiff(), cons = g)\noptprob = OptimizationProblem(optf, [0.0], lb = [0.0], ub = [1.0], lcons = fill(-Inf, 91),\n    ucons = fill(0.05, 91))\nmin_intervention_strength = solve(optprob,\n    OptimizationMOI.MOI.OptimizerWithAttributes(NLopt.Optimizer,\n        \"algorithm\" => :GN_ORIG_DIRECT,\n        \"maxtime\" => 60.0))\nmin_intervention_strength.u","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"res = zeros(91)\ng(res, min_intervention_strength.u)\nmaximum(res[1:91])","category":"page"},{"location":"scenarios/scenario2/#Question-5","page":"Scenario 2: Limiting Hospitalizations","title":"Question 5","text":"","category":"section"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"Now assume that instead of NPIs, the Board wants to focus all their resources on an aggressive vaccination campaign to increase the fraction of the total population that is vaccinated. What is the minimum intervention with vaccinations required in order for this intervention to have the same impact on cases and hospitalizations, as your optimal answer from question 3? Depending on the model you use, this may be represented as an increase in total vaccinated population, or increase in daily vaccination rate (% of eligible people vaccinated each day), or some other representation.","category":"page"},{"location":"scenarios/scenario2/","page":"Scenario 2: Limiting Hospitalizations","title":"Scenario 2: Limiting Hospitalizations","text":"This requires an additional model structure, not very interesting to showcase the SciML stack.","category":"page"},{"location":"tutorials/sensitivity_analysis/#Sensitivity-Analysis","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"","category":"section"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"In this tutorial, we will showcase how to perform global sensitivity analysis of a model. To get started, let's first pull in our modified second order ODE Lorenz equation model from before:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"using EasyModelAnalysis\n\n@parameters t σ ρ β\n@variables x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(D(x)) ~ σ * (y - x),\n    D(y) ~ x * (ρ - z) - y,\n    D(z) ~ x * y - β * z]\n\n@named sys = ODESystem(eqs)\nsys = structural_simplify(sys)\n\nu0 = [D(x) => 2.0,\n    x => 1.0,\n    y => 0.0,\n    z => 0.0]\n\np = [σ => 28.0,\n    ρ => 10.0,\n    β => 8 / 3]\n\ntspan = (0.0, 100.0)\nprob = ODEProblem(sys, u0, tspan, p, jac = true)\nsol = solve(prob)","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"On this model, we wish to perform sensitivity analyses. Global sensitivity analysis requires the specification of two things:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"Global sensitivity of what? What is the value to be measured from the model that you want to assess the sensitivity of?\nOver what space of parameter values? This is a box of potential values for the parameters of the model.","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"The function get_sensitivity(prob, t, obs, bounds) first takes (t,obs), where t is the time point to take measurements from the model and y is the desired observable to measure. bounds is specified as an array of pairs, which maps parameter symbols to arrays specifying the lower and upper bounds of its parameter range.","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"Thus for example, let's calculate the sensitivity of y(100) over the parameters (ρ, β) where rho in 020 and beta in 0100:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"pbounds = [ρ => [0.0, 20.0], β => [0.0, 100.0]]\nsensres = get_sensitivity(prob, 100.0, y, pbounds; samples = 2000)","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"The output shows values of first_order, second_order and total_order sensitivities. These are quantities that define the nonlinear effect of the variables on the output. The first order values can be thought of as the independent interaction effects, similar to the values of a linear regression for R^2, i.e. it's the variance explained by independent effects of a given parameter. The first indices are the scaled variance terms, for example:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"ρ_first_order = V[y(100) changing only ρ] / V[y(100)]","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"where V denotes the variance. I.e., ρ_first_order is the percentage of variance explained by only changing ρ. Being normalized, if the model is linear then ρ_first_order + β_first_order == 1, and thus its total summation tells us the degree of nonlinearity. Our simulation here has the sum of first indices as <0.2, an indication of a high degree of nonlinear interaction between the measured output and the parameters.","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"The second order indices then say how much can be attributed to changes of combinations of variables. I.e.:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"ρ_β_second_order = V[y(100) changing only ρ and β] / V[y(100)]","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"which thus gives the percentage of variance explained by the nonlinearities of ρ and β combined. These sensitivity functions only output up to the second indices, since there is a combinatorial explosion in the number of terms that need to be computed for models with more parameters. However, in this tutorial there are only two variables, and thus all variance should be explained by just these two parameters. This means that ρ_first_order + β_first_order + ρ_β_second_order should be approximately equal to 1, as all variance should be explained by the linearity or second order interactions between the two variables. Let's check this in action:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"sensres[:ρ_first_order] + sensres[:β_first_order] + sensres[:ρ_β_second_order]","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"This is not exactly equal to 1 due to the numerical error in the integral approximations, but you can see theory in action! (Also, this is a good test for correctness of the implementation).","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"Now, if you had more than two variables, is there a good way to get a sense of the “sensitivity due to ρ”? Using the first indices is a bad approximation to this value, since it's only the measurement of the independent or linear sensitivity of the output due to ρ. Instead, what one would want to do, is to get the sum of the first order index ρ_first_order, plus all second order effects which include ρ, plus all third order effects that include ρ, plus … all the way to the Nth order for N variables. Surprisingly, this summation can be computed without requiring the computation of all the higher order indices. This is known as the “total order index” of a variable. In a two parameter model, we can see this in action:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"sensres[:ρ_first_order] + sensres[:ρ_β_second_order], sensres[:ρ_total_order]","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"sensres[:β_first_order] + sensres[:ρ_β_second_order], sensres[:β_total_order]","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"Thus, the total indices are a good measurement of the relative size of the total effect of each parameter on the solution of the model.","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"In summary:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"First order indices showcase the amount of linearity and the direct linear attributions to each variable\nThe second order indices show the linear correlations in the outputs\nThe total indices measure the total effect a given variable has on the variance of the output","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"and notably, all values are normalized relative quantities.","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"Thus we can finally use the create_sensitivity_plot function to visualize the field of sensitivity results:","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"create_sensitivity_plot(prob, 100.0, y, pbounds; samples = 2000)","category":"page"},{"location":"tutorials/sensitivity_analysis/","page":"Sensitivity Analysis","title":"Sensitivity Analysis","text":"which shows the relative sizes of the values in plots for the first, second, and total index values.","category":"page"},{"location":"tutorials/datafitting/#Calibrating-Models-to-Data","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"","category":"section"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"In this tutorial, we will showcase the tooling for fitting models to data. Let's take our favorite 2nd order Lorenz equation form as our model:","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"using EasyModelAnalysis\n\n@parameters t σ ρ β\n@variables x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(D(x)) ~ σ * (y - x),\n    D(y) ~ x * (ρ - z) - y,\n    D(z) ~ x * y - β * z]\n\n@named sys = ODESystem(eqs)\nsys = structural_simplify(sys)\n\nu0 = [D(x) => 2.0,\n    x => 1.0,\n    y => 0.0,\n    z => 0.0]\n\np = [σ => 28.0,\n    ρ => 10.0,\n    β => 8 / 3]\n\ntspan = (0.0, 100.0)\nprob = ODEProblem(sys, u0, tspan, p, jac = true)\nsol = solve(prob)","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"Let's create a dataset with some set of parameters, and show how the datafit function can be used to discover the parameters that generated the data. To start, let's show the data format by generating a dataset. A dataset contains an array t of the time points for the data, and maps [observable => timeseries] where the timeseries is an array of values for the observable at the time points of t. We can use the get_timeseries function to generate a dataset like:","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"tsave = [1.0, 2.0, 3.0]\ndata = [x => get_timeseries(prob, x, tsave), z => get_timeseries(prob, z, tsave)]","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"Now let's do a datafit. We need to choose initial parameters for the fitting process and call the datafit:","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"psub_ini = [σ => 27.0, β => 3.0]\nfit = datafit(prob, psub_ini, tsave, data)","category":"page"},{"location":"tutorials/datafitting/","page":"Calibrating Models to Data","title":"Calibrating Models to Data","text":"Recall that our starting parameters, the parameters the dataset was generated from, was [σ => 28.0, ρ => 10.0, β => 8 / 3]. Looks like this did a good job at recovering them!","category":"page"},{"location":"api/basic_queries/#Basic-Queries","page":"Basic Queries","title":"Basic Queries","text":"","category":"section"},{"location":"api/basic_queries/#Timeseries","page":"Basic Queries","title":"Timeseries","text":"","category":"section"},{"location":"api/basic_queries/","page":"Basic Queries","title":"Basic Queries","text":"get_timeseries","category":"page"},{"location":"api/basic_queries/#EasyModelAnalysis.get_timeseries","page":"Basic Queries","title":"EasyModelAnalysis.get_timeseries","text":"get_timeseries(prob, sym, t)\n\nGet the time-series of state sym evaluated at times t.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#Extrema","page":"Basic Queries","title":"Extrema","text":"","category":"section"},{"location":"api/basic_queries/","page":"Basic Queries","title":"Basic Queries","text":"get_min_t\nget_max_t\nplot_extrema\nphaseplot_extrema","category":"page"},{"location":"api/basic_queries/#EasyModelAnalysis.get_min_t","page":"Basic Queries","title":"EasyModelAnalysis.get_min_t","text":"get_min_t(prob, sym)\nget_min_t(sol, sym)\n\nReturns (t,min) where t is the timepoint where sym reaches its minimum min in the interval prob.tspan.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.get_max_t","page":"Basic Queries","title":"EasyModelAnalysis.get_max_t","text":"get_max_t(prob, sym)\nget_max_t(sol, sym)\n\nReturns (t,max) where t is the timepoint where sym reaches its maximum max in the interval prob.tspan.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.plot_extrema","page":"Basic Queries","title":"EasyModelAnalysis.plot_extrema","text":"plot_extrema(prob, sym)\n\nPlots the solution of the observable sym along with showcasing time points where it obtains its maximum and minimum values.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.phaseplot_extrema","page":"Basic Queries","title":"EasyModelAnalysis.phaseplot_extrema","text":"phaseplot_extrema(prob, sym, plotsyms)\n\nPlots the phase plot solution of the observable sym along with showcasing time points where it obtains its maximum and minimum values. plotsyms should be given as the tuple of symbols for the observables that define the axis of the phase plot.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#Forecasting","page":"Basic Queries","title":"Forecasting","text":"","category":"section"},{"location":"api/basic_queries/","page":"Basic Queries","title":"Basic Queries","text":"get_uncertainty_forecast\nget_uncertainty_forecast_quantiles\nplot_uncertainty_forecast\nplot_uncertainty_forecast_quantiles","category":"page"},{"location":"api/basic_queries/#EasyModelAnalysis.get_uncertainty_forecast","page":"Basic Queries","title":"EasyModelAnalysis.get_uncertainty_forecast","text":"get_uncertainty_forecast(prob, sym, t, uncertainp, samples)\n\nGet the ensemble of time-series of state sym evaluated at times t for solutions with uncertain parameters specified according to the distributions in uncertainp. The distributions are specified in the form [sym1 => dist1, sym2 => dist2] where dist is a Distributions.jl distribution. Samples is the number of trajectories to run.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.get_uncertainty_forecast_quantiles","page":"Basic Queries","title":"EasyModelAnalysis.get_uncertainty_forecast_quantiles","text":"getuncertaintyforecast_quantiles(prob, sym, t, uncertainp, samples, quants = (0.05, 0.95))\n\nGet the ensemble of time-series of state sym evaluated at times t for solutions with uncertain parameters specified according to the distributions in uncertainp. The distributions are specified in the form [sym1 => dist1, sym2 => dist2] where dist is a Distributions.jl distribution. Samples is the number of trajectories to run.\n\nReturns a tuple of arrays for the quantiles quants which defaults to the 95% confidence intervals.\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.plot_uncertainty_forecast","page":"Basic Queries","title":"EasyModelAnalysis.plot_uncertainty_forecast","text":"plot_uncertainty_forecast(prob, sym, t, uncertainp, samples)\n\n\n\n\n\n","category":"function"},{"location":"api/basic_queries/#EasyModelAnalysis.plot_uncertainty_forecast_quantiles","page":"Basic Queries","title":"EasyModelAnalysis.plot_uncertainty_forecast_quantiles","text":"plot_uncertainty_forecast_quantiles(prob, sym, t, uncertainp, samples, quants = (0.05, 0.95))\n\n\n\n\n\n","category":"function"},{"location":"examples/Carcione2020/#Sensitivity-Analysis-of-the-Carcione2020-Epidemic-Model","page":"Sensitivity Analysis of the Carcione2020 Epidemic Model","title":"Sensitivity Analysis of the Carcione2020 Epidemic Model","text":"","category":"section"},{"location":"examples/Carcione2020/","page":"Sensitivity Analysis of the Carcione2020 Epidemic Model","title":"Sensitivity Analysis of the Carcione2020 Epidemic Model","text":"cd(@__DIR__)\nusing SBMLToolkit, ModelingToolkit, EasyModelAnalysis, UnPack\n\nxmlfile = \"../assets/Carcione2020.xml\"\n\nSBMLToolkit.checksupport_file(xmlfile)\nmdl = readSBML(xmlfile, doc -> begin\n    set_level_and_version(3, 2)(doc)\n    convert_simplify_math(doc)\nend)\n\nrs = ReactionSystem(mdl)  # If you want to create a reaction system\nodesys = convert(ODESystem, rs)  # Alternatively: ODESystem(mdl)","category":"page"},{"location":"examples/Carcione2020/","page":"Sensitivity Analysis of the Carcione2020 Epidemic Model","title":"Sensitivity Analysis of the Carcione2020 Epidemic Model","text":"sys = structural_simplify(odesys)","category":"page"},{"location":"examples/Carcione2020/","page":"Sensitivity Analysis of the Carcione2020 Epidemic Model","title":"Sensitivity Analysis of the Carcione2020 Epidemic Model","text":"@unpack Infected, Exposed, Deceased, Recovered, Total_population, Susceptible = sys\n@unpack alpha, epsilon, gamma, mu, beta, City = sys\ntspan = (0.0, 1.0)\nprob = ODEProblem(odesys, [], tspan, [])\nsol = solve(prob, Rodas5())\nplot(sol, idxs = Deceased)","category":"page"},{"location":"examples/Carcione2020/","page":"Sensitivity Analysis of the Carcione2020 Epidemic Model","title":"Sensitivity Analysis of the Carcione2020 Epidemic Model","text":"pbounds = [\n    alpha => [0.003, 0.006],\n    epsilon => [1 / 6, 1 / 2],\n    gamma => [0.1, 0.2],\n    mu => [0.01, 0.02],\n    beta => [0.7, 0.9],\n]\ncreate_sensitivity_plot(prob, 100.0, Deceased, pbounds; samples = 2000)","category":"page"},{"location":"examples/SEIRHD/#Analysis-of-Interventions-On-The-SEIRHD-Epidemic-Model","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"","category":"section"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"First, let's implement the classic SEIRHD epidemic model with ModelingToolkit:","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"using EasyModelAnalysis\n@variables t\nDₜ = Differential(t)\n@variables S(t)=0.9 E(t)=0.05 I(t)=0.01 R(t)=0.2 H(t)=0.1 D(t)=0.01\n@variables T(t)=0.0 η(t)=0.0 cumulative_I(t)=0.0\n@parameters β₁=0.6 β₂=0.143 β₃=0.055 α=0.003 γ₁=0.007 γ₂=0.011 δ=0.1 μ=0.14\neqs = [T ~ S + E + I + R + H + D\n    η ~ (β₁ * E + β₂ * I + β₃ * H) / T\n    Dₜ(S) ~ -η * S\n    Dₜ(E) ~ η * S - α * E\n    Dₜ(I) ~ α * E - (γ₁ + δ) * I\n    Dₜ(cumulative_I) ~ I\n    Dₜ(R) ~ γ₁ * I + γ₂ * H\n    Dₜ(H) ~ δ * I - (μ + γ₂) * H\n    Dₜ(D) ~ μ * H];\n@named seirhd = ODESystem(eqs)\nseirhd = structural_simplify(seirhd)\nprob = ODEProblem(seirhd, [], (0, 110.0))\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"Let's solve a few problems:","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"Provide a forecast of cumulative Covid-19 cases and deaths over the 6-week period from May 1 – June 15, 2020 under no interventions, including 90% prediction intervals in your forecasts. Compare the accuracy of the forecasts with true data over the six-week timespan.","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"get_uncertainty_forecast(prob, [cumulative_I], 0:100, [β₁ => Uniform(0.0, 1.0)], 6 * 7)","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"plot_uncertainty_forecast(prob, [cumulative_I], 0:100, [β₁ => Uniform(0.0, 1.0)], 6 * 7)","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"get_uncertainty_forecast_quantiles(prob, [cumulative_I], 0:100, [β₁ => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"plot_uncertainty_forecast_quantiles(prob, [cumulative_I], 0:100, [β₁ => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"examples/SEIRHD/","page":"Analysis of Interventions On The SEIRHD Epidemic Model","title":"Analysis of Interventions On The SEIRHD Epidemic Model","text":"Based on the forecasts, do we need additional interventions to keep cumulative Covid deaths under 6000 total? Provide a probability that the cumulative number of Covid deaths will stay under 6000 for the next 6 weeks without any additional interventions.","category":"page"},{"location":"tutorials/ensemble_modeling/#Ensemble-Modeling","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Ensemble modeling is the process of building predictors which are combinations of predictive models. In this tutorial we will show how to use EMA.jl to build such ensemble models.","category":"page"},{"location":"tutorials/ensemble_modeling/#The-Predictive-Models","page":"Ensemble Modeling","title":"The Predictive Models","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"For this tutorial we will use a set of SIR-type models as the basis. In particular, we will use a basic SIR model, an SIRHD, and an SIRHD model with vaccintation. The construction of the models is as follows:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"using EasyModelAnalysis, LinearAlgebra\n\n@parameters t β=0.05 c=10.0 γ=0.25\n@variables S(t)=990.0 I(t)=10.0 R(t)=0.0\n∂ = Differential(t)\nN = S + I + R # This is recognized as a derived variable\neqs = [∂(S) ~ -β * c * I / N * S,\n    ∂(I) ~ β * c * I / N * S - γ * I,\n    ∂(R) ~ γ * I];\n\n@named sys = ODESystem(eqs);\ntspan = (0, 30)\nprob = ODEProblem(sys, [], tspan);\n\n@parameters t β=0.1 c=10.0 γ=0.25 ρ=0.1 h=0.1 d=0.1 r=0.1\n@variables S(t)=990.0 I(t)=10.0 R(t)=0.0 H(t)=0.0 D(t)=0.0\n∂ = Differential(t)\nN = S + I + R + H + D # This is recognized as a derived variable\neqs = [∂(S) ~ -β * c * I / N * S,\n    ∂(I) ~ β * c * I / N * S - γ * I - h * I - ρ * I,\n    ∂(R) ~ γ * I + r * H,\n    ∂(H) ~ h * I - r * H - d * H,\n    ∂(D) ~ ρ * I + d * H];\n\n@named sys2 = ODESystem(eqs);\n\nprob2 = ODEProblem(sys2, [], tspan);\n\n@parameters t β=0.1 c=10.0 γ=0.25 ρ=0.1 h=0.1 d=0.1 r=0.1 v=0.1\n@parameters t β2=0.1 c2=10.0 ρ2=0.1 h2=0.1 d2=0.1 r2=0.1\n@variables S(t)=990.0 I(t)=10.0 R(t)=0.0 H(t)=0.0 D(t)=0.0\n@variables Sv(t)=0.0 Iv(t)=0.0 Rv(t)=0.0 Hv(t)=0.0 Dv(t)=0.0\n@variables I_total(t)\n\n∂ = Differential(t)\nN = S + I + R + H + D + Sv + Iv + Rv + Hv + Dv # This is recognized as a derived variable\neqs = [∂(S) ~ -β * c * I_total / N * S - v * Sv,\n    ∂(I) ~ β * c * I_total / N * S - γ * I - h * I - ρ * I,\n    ∂(R) ~ γ * I + r * H,\n    ∂(H) ~ h * I - r * H - d * H,\n    ∂(D) ~ ρ * I + d * H,\n    ∂(Sv) ~ -β2 * c2 * I_total / N * Sv + v * Sv,\n    ∂(Iv) ~ β2 * c2 * I_total / N * Sv - γ * Iv - h2 * Iv - ρ2 * Iv,\n    ∂(Rv) ~ γ * I + r2 * H,\n    ∂(Hv) ~ h2 * I - r2 * H - d2 * H,\n    ∂(Dv) ~ ρ2 * I + d2 * H,\n    I_total ~ I + Iv,\n];\n\n@named sys3 = ODESystem(eqs)\nsys3 = structural_simplify(sys3)\nprob3 = ODEProblem(sys3, [], tspan);","category":"page"},{"location":"tutorials/ensemble_modeling/#Representing-Ensemble-Models-with-the-SciML-EnsembleProblem","page":"Ensemble Modeling","title":"Representing Ensemble Models with the SciML EnsembleProblem","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"The SciML libraries allow for what's known as an EnsembleProblem, which is an object that solves many simultainous problems and represents the aggregate solution. This object is documented in the DifferentialEquations.jl documentation and has all kinds of features, such as automated GPU acceleration, though we will instead focus just on the subset of features required for this demonstration. To build an EnsembleProblem, the main object is the prob_func, which is a function of (prob,i,repeat) which describes what the ith problem should be. The prob in this case is a prototype problem, which we are effectively ignoring for our use case.","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Thus a simple EnsembleProblem which ensembles the three models built above is as follows:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"probs = [prob, prob2, prob3]\nenprob = EnsembleProblem(probs)","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Here, prob_func returns model i on the ith iteration, and thus if we solve with 3 trajectories we will get the solution to all three models. This looks like:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"sol = solve(enprob; saveat = 1);","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"We can access the 3 solutions as sol[i] respectively. Let's get the time series for S from each of the models:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"sol[:,S]","category":"page"},{"location":"tutorials/ensemble_modeling/#Building-a-Dataset","page":"Ensemble Modeling","title":"Building a Dataset","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Now let's build a dataset from our ensemble model. We will make our dataset for S, I, and R by taking a linear combination of our models and using the aforementioned interface on the ensemble solution.","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"weights = [0.2, 0.5, 0.3]\ndata = [\n    S => vec(sum(stack(weights .* sol[:,S]), dims = 2)),\n    I => vec(sum(stack(weights .* sol[:,I]), dims = 2)),\n    R => vec(sum(stack(weights .* sol[:,R]), dims = 2)),\n]","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol; idxs = S)\nscatter!(data[1][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol; idxs = I)\nscatter!(data[2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol; idxs = R)\nscatter!(data[3][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Now let's split that into training, ensembling, and forecast sections:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"fullS = vec(sum(stack(weights .* sol[:,S]),dims=2))\nfullI = vec(sum(stack(weights .* sol[:,I]),dims=2))\nfullR = vec(sum(stack(weights .* sol[:,R]),dims=2))\n\nt_train = 0:14\ndata_train = [\n    S => (t_train,fullS[1:15]),\n    I => (t_train,fullI[1:15]),\n    R => (t_train,fullR[1:15]),\n]\nt_ensem = 0:21\ndata_ensem = [\n    S => (t_ensem,fullS[1:22]),\n    I => (t_ensem,fullI[1:22]),\n    R => (t_ensem,fullR[1:22]),\n]\nt_forecast = 0:30\ndata_forecast = [\n    S => (t_forecast,fullS),\n    I => (t_forecast,fullI),\n    R => (t_forecast,fullR),\n]","category":"page"},{"location":"tutorials/ensemble_modeling/#Bayesian-Calibration","page":"Ensemble Modeling","title":"Bayesian Calibration","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Now let's perform a Bayesian calibration on each of the models. This gives us multiple parameterizations for each model, which then gives an ensemble which is parameterizations x models in size.","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"probs = [prob, prob2, prob3]\nps = [[β => Uniform(0.01, 10.0), γ => Uniform(0.01, 10.0)] for i in 1:3]\ndatas = [data_train,data_train,data_train]\nenprobs = bayesian_ensemble(probs, ps, datas)","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Let's see how each of our models in the ensemble compare against the data when changed to use the fit parameters:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"sol = solve(enprobs);\n\nplot(sol; idxs = S)\nscatter!(t_train, data_train[1][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol; idxs = I)\nscatter!(t_train, data_train[2][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol; idxs = R)\nscatter!(t_train, data_train[3][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/#Training-the-Ensemble-Model","page":"Ensemble Modeling","title":"Training the Ensemble Model","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Now let's train the ensemble model. We will do that by solving a bit further than the calibration step. Let's build that solution data:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"plot(sol;idxs = S)\nscatter!(t_ensem,data_ensem[1][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"We can obtain the optimal weights for ensembling by solving a linear regression of the solution's data against the wanted trajectory:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"sol = solve(enprobs; saveat = t_ensem);\nensem_weights = ensemble_weights(sol, data_ensem)","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Now we can extrapolate forward with these ensemble weights as follows:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"sol = solve(enprobs; saveat = t_ensem);\nensem_prediction = sum(stack(ensem_weights .* sol[:,S]), dims = 2)\nplot(sol; idxs = S, color = :blue)\nplot!(t_ensem, ensem_prediction, lw = 5, color = :red)\nscatter!(t_ensem, data_ensem[1][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"ensem_prediction = sum(stack(ensem_weights .* sol[:,I]), dims = 2)\nplot(sol; idxs = I, color = :blue)\nplot!(t_ensem, ensem_prediction, lw = 3, color = :red)\nscatter!(t_ensem, data_ensem[2][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/#Forecasting-the-Trained-Ensemble","page":"Ensemble Modeling","title":"Forecasting the Trained Ensemble","text":"","category":"section"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"Once we have obtained the ensemble model, we can forecast ahead with it:","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"forecast_probs = [remake(enprobs.prob[i]; tspan = (t_train[1],t_forecast[end])) for i in 1:length(enprobs.prob)]\nfit_enprob = EnsembleProblem(forecast_probs)\n\nsol = solve(fit_enprob; saveat = t_forecast);\nensem_prediction = sum(stack(ensem_weights .* sol[:,S]), dims = 2)\nplot(sol; idxs = S, color = :blue)\nplot!(t_forecast, ensem_prediction, lw = 3, color = :red)\nscatter!(t_forecast, data_forecast[1][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"ensem_prediction = sum(stack([ensem_weights[i] * sol[i][I] for i in 1:length(forecast_probs)]), dims = 2)\nplot(sol; idxs = I, color = :blue)\nplot!(t_forecast, ensem_prediction, lw = 3, color = :red)\nscatter!(t_forecast, data_forecast[2][2][2])","category":"page"},{"location":"tutorials/ensemble_modeling/","page":"Ensemble Modeling","title":"Ensemble Modeling","text":"ensem_prediction = sum(stack([ensem_weights[i] * sol[i][R] for i in 1:length(forecast_probs)]), dims = 2)\nplot(sol; idxs = R, color = :blue)\nplot!(t_forecast, ensem_prediction, lw = 3, color = :red)\nscatter!(t_forecast, data_forecast[3][2][2])","category":"page"},{"location":"scenarios/scenario4/#Scenario-4:-Testing-and-Return-to-Campus","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"","category":"section"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"Load packages:","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"using EasyModelAnalysis\nusing AlgebraicPetri\nusing UnPack\nusing Dates","category":"page"},{"location":"scenarios/scenario4/#Assumptions-from-the-Scenario","page":"Scenario 4: Testing and Return to Campus","title":"Assumptions from the Scenario","text":"","category":"section"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"University of Michigan (Ann Arbor campus) QUESTION: TA1 reachback for total population?","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"#=\nFrom: https://obp.umich.edu/wp-content/uploads/pubdata/almanac/Almanac_Ch1_June2022.pdf#:~:text=Based%20on%20the%20November%202021,All%20other%20staff%20total%2015%2C795.\nUndergraduate Students ................................ 32,282\nGraduate Students ......................................... 15,268\nProfessional Students...................................... 2,728\nTenured/Tenure-Track Faculty........................ 3,136\nLecturers.......................................................... 1,044\nClinical Faculty ............................................... 2,268\nResearch Faculty ................................................ 868\nOther Academic ................................................. 403\nResearch Fellows/Post-Doctoral Fellows........ 1,105\nStaff............................................................... 15,795\nAnn Arbor Campus Total1............................. 74,897\n=#\n\nN_ugrad = 32_282\nN_grad = 15_268 + 2_728\nN_staff = 3_136 + 1_044 + 2_268 + 868 + 403 + 1_105 + 15_795\nNN = N_ugrad + N_grad + N_staff","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"Assume the following numbers of true infections at the onset of the term by population type: Undergraduate=750 Graduate/professional=250 Faculty/staff=100","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"I_ugrad = 750\nI_grad = 250\nI_staff = 100","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"Time/Setting: It is late 2021 and you are planning for the Spring 2022 term at the University of Michigan (Ann Arbor campus) beginning in early January 2022. For the purpose of this scenario, consider a four-month period that begins > January 1st and ends May 1st.","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"tstart = Date(2022, 01, 01)\ntend = Date(2022, 05, 01)\ntdays = (tend - tstart).value","category":"page"},{"location":"scenarios/scenario4/#Generate-the-Model-and-Dataset","page":"Scenario 4: Testing and Return to Campus","title":"Generate the Model and Dataset","text":"","category":"section"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"function formSEIISRD()\n    SEIRHD = LabelledPetriNet([:S, :E, :I, :IS, :R, :D],\n        :expo => ((:S, :I) => (:E, :I)),\n        :conv => (:E => :I),\n        :rec => (:I => :R),\n        :test => (:I => :IS),\n        :leave => (:IS => :R),\n        :death => (:I => :D))\n    return SEIRHD\nend\nsys1 = ODESystem(formSEIISRD())\n\n@unpack S, E, I, IS, R, D = sys1\n@unpack expo, conv, rec, test, leave, death = sys1\n\n@parameters u_expo=0.1 * NN u_conv=0.1 * NN u_rec=0.8 * NN u_death=0.1 * NN u_test=0.9 * NN u_leave=0.2 *\n                                                                                                    NN N=NN\ntranslate_params = [expo => u_expo / NN,\n    conv => u_conv / NN,\n    rec => u_rec / NN,\n    death => u_death / NN,\n    test => u_test / NN,\n    leave => u_leave / NN,\n]\nsubed_sys = substitute(sys1, translate_params)\nsys = add_accumulations(subed_sys, [I])\n@unpack accumulation_I = sys","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"I_total = I_ugrad + I_grad + I_staff\nu0init = [\n    S => NN - I_total,\n    E => 0,\n    I => I_total,\n    IS => 0,\n    R => 0,\n    D => 0,\n]\n\nprob = ODEProblem(sys, u0init, (0.0, tdays))\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"scenarios/scenario4/#Model-Analysis","page":"Scenario 4: Testing and Return to Campus","title":"Model Analysis","text":"","category":"section"},{"location":"scenarios/scenario4/#Question-1","page":"Scenario 4: Testing and Return to Campus","title":"Question 1","text":"","category":"section"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"Define a return-to-campus strategy that minimizes total testing while maintaining infections below the initial isolation bed capacity of 430. The testing scheme can include an arrival testing strategy in addition to unique testing approaches within time periods of the simulation. Cohorts can have unique testing strategies defined by test type and number per week.","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"# Minimize u_test subject to IS <= 430\np_opt, s2, ret = optimal_parameter_threshold(prob, IS, 430, u_test, [u_test], [0.0], [NN],\n    maxtime = 10);\nplot(s2, idxs = [IS])","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"p_opt, s2, ret = optimal_parameter_threshold(prob, D, 430, u_test, [u_test], [0.0], [NN],\n    maxtime = 10);\nplot(s2, idxs = [I, IS, D])","category":"page"},{"location":"scenarios/scenario4/#Question-4","page":"Scenario 4: Testing and Return to Campus","title":"Question 4","text":"","category":"section"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"Challenge question: assume that antigen tests are one fifth the cost of PCR tests but also much less (~half) as sensitive. Incorporate the cost of the testing program into your recommendations.","category":"page"},{"location":"scenarios/scenario4/","page":"Scenario 4: Testing and Return to Campus","title":"Scenario 4: Testing and Return to Campus","text":"# Minimize u_test subject to IS <= 430\np_opt, s2, ret = optimal_parameter_threshold(prob, IS, 430, 5 * u_test, [u_test], [0.0],\n    [NN], maxtime = 10);\nplot(s2, idxs = [IS])","category":"page"},{"location":"api/threshold_interventions/#Threshold-Interventions","page":"Threshold Interventions","title":"Threshold Interventions","text":"","category":"section"},{"location":"api/threshold_interventions/","page":"Threshold Interventions","title":"Threshold Interventions","text":"stop_at_threshold\noptimal_threshold_intervention\noptimal_parameter_intervention_for_threshold","category":"page"},{"location":"api/threshold_interventions/#EasyModelAnalysis.stop_at_threshold","page":"Threshold Interventions","title":"EasyModelAnalysis.stop_at_threshold","text":"stop_at_threshold(prob, obs, threshold)\n\nSimulates prob until obs == threshold.\n\n\n\n\n\n","category":"function"},{"location":"api/threshold_interventions/#EasyModelAnalysis.optimal_threshold_intervention","page":"Threshold Interventions","title":"EasyModelAnalysis.optimal_threshold_intervention","text":"optimal_threshold_intervention(prob, [p1 = prob.p], p2, obs, threshold, duration; maxtime)\n\nArguments\n\np1: parameters for the pre-intervention scenario. Defaults to prob.p.\np2: parameters for the pose-intervention scenario.\nobs: The observation symbolic expression.\nthreshold: The threshold for the observation.\nduration: Duration for the evaluation of intervention.\n\nKeyword Arguments\n\nmaxtime: Maximum optimization time. Defaults to 60.\n\nReturns\n\nopt_tspan: Optimal intervention time span.\n(s1, s2, s3): Pre-intervention, intervention, post-intervention solutions.\nret: Return code from the optimization.\n\n\n\n\n\n","category":"function"},{"location":"api/threshold_interventions/#EasyModelAnalysis.optimal_parameter_intervention_for_threshold","page":"Threshold Interventions","title":"EasyModelAnalysis.optimal_parameter_intervention_for_threshold","text":"optimal_parameter_intervention_for_threshold(prob, obs, threshold, cost, ps,\n    lb, ub, intervention_tspan, duration; ineq_cons = nothing, maxtime=60)\n\nArguments\n\nprob: An ODEProblem.\nobs: The observation symbolic expression.\nthreshold: The threshold for the observation.\ncost: the cost function for minimization, e.g. α + 20 * β.\nps: the parameters that appear in the cost, e.g. [α, β].\nlb: the lower bounds of the parameters e.g. [-10, -5].\nub: the upper bounds of the parameters e.g. [5, 10].\nintervention_tspan: intervention time span, e.g. (20.0, 30.0). Defaults to prob.tspan.\nduration: Duration for the evaluation of intervention. Defaults to prob.tspan[2] - prob.tspan[1].\n\nKeyword Arguments\n\nmaxtime: Maximum optimization time. Defaults to 60.\nineq_cons: a vector of symbolic expressions in terms of symbolic parameters. The optimizer will enforce ineq_cons .< 0.\n\nReturns\n\nopt_p: Optimal intervention parameters.\n(s1, s2, s3): Pre-intervention, intervention, post-intervention solutions.\nret: Return code from the optimization.\n\n\n\n\n\n","category":"function"},{"location":"scenarios/scenario3/#Scenario-3:-Limiting-Deaths","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Load packages:","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"using EasyModelAnalysis\nusing AlgebraicPetri\nusing UnPack","category":"page"},{"location":"scenarios/scenario3/#Generate-the-Model-and-Dataset","page":"Scenario 3: Limiting Deaths","title":"Generate the Model and Dataset","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"function formSEIRHD()\n    SEIRHD = LabelledPetriNet([:S, :E, :I, :R, :H, :D],\n        :expo => ((:S, :I) => (:E, :I)),\n        :conv => (:E => :I),\n        :rec => (:I => :R),\n        :hosp => (:I => :H),\n        :death => (:H => :D))\n    return SEIRHD\nend\n\nseirhd = formSEIRHD()\nsys1 = ODESystem(seirhd)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"function formSEIRD()\n    SEIRD = LabelledPetriNet([:S, :E, :I, :R, :D],\n        :expo => ((:S, :I) => (:E, :I)),\n        :conv => (:E => :I),\n        :rec => (:I => :R),\n        :death => (:I => :D))\n    return SEIRD\nend\n\nseird = formSEIRD()\nsys2 = ODESystem(seird)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"function formSIRHD()\n    SIRHD = LabelledPetriNet([:S, :I, :R, :H, :D],\n        :expo => ((:S, :I) => (:I, :I)),\n        :rec => (:I => :R),\n        :hosp => (:I => :H),\n        :death => (:H => :D))\n    return SIRHD\nend\n\nsirhd = formSIRHD()\nsys3 = ODESystem(sirhd)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"function form_seird_renew()\n    seird_renew = LabelledPetriNet([:S, :E, :I, :R, :D],\n        :expo => ((:S, :I) => (:E, :I)),\n        :conv => (:E => :I),\n        :rec => (:I => :R),\n        :death => (:I => :D),\n        :renew => (:R => :S))\n    return seird_renew\nend\n\nseird_renew = form_seird_renew()\nsys4 = ODESystem(seird_renew)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"using ASKEM # Hack, remove when merged\nmax_e_h = mca(seird, sirhd)\nAlgebraicPetri.Graph(max_e_h[1])","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"max_3way = mca(max_e_h[1], seirhd)\nAlgebraicPetri.Graph(max_3way[1])","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"max_seird_renew = mca(seird, seird_renew)\nAlgebraicPetri.Graph(max_seird_renew[1])","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"t = ModelingToolkit.get_iv(sys1)\n@unpack S, E, I, R, H, D = sys1\n@unpack expo, conv, rec, hosp, death = sys1\nNN = 10.0\n@parameters u_expo=0.2 * NN u_conv=0.2 * NN u_rec=0.8 * NN u_hosp=0.2 * NN u_death=0.1 * NN N=NN\ntranslate_params = [expo => u_expo / N,\n    conv => u_conv / N,\n    rec => u_rec / N,\n    hosp => u_hosp / N,\n    death => u_death / N]\nsubed_sys = substitute(sys1, translate_params)\nsys = add_accumulations(subed_sys, [I])\n@unpack accumulation_I = sys","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"u0init = [\n    S => 0.9 * NN,\n    E => 0.05 * NN,\n    I => 0.01 * NN,\n    R => 0.02 * NN,\n    H => 0.01 * NN,\n    D => 0.01 * NN,\n]\n\ntend = 6 * 7\nts = 0:tend\nprob = ODEProblem(sys, u0init, (0.0, tend))\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"scenarios/scenario3/#Model-Analysis","page":"Scenario 3: Limiting Deaths","title":"Model Analysis","text":"","category":"section"},{"location":"scenarios/scenario3/#Question-1","page":"Scenario 3: Limiting Deaths","title":"Question 1","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Provide a forecast of cumulative Covid-19 cases and deaths over the 6-week period from May 1 – June 15, 2020 under no interventions, including 90% prediction intervals in your forecasts. Compare the accuracy of the forecasts with true data over the six-week timespan.","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"get_uncertainty_forecast(prob, [accumulation_I], ts, [u_conv => Uniform(0.0, 1.0)], 6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast(prob, [accumulation_I], ts, [u_conv => Uniform(0.0, 1.0)], 6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"get_uncertainty_forecast_quantiles(prob, [accumulation_I], ts,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast_quantiles(prob, [accumulation_I], ts,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/#Question-2","page":"Scenario 3: Limiting Deaths","title":"Question 2","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Based on the forecasts, do we need additional interventions to keep cumulative Covid deaths under 6000 total? Provide a probability that the cumulative number of Covid deaths will stay under 6000 for the next 6 weeks without any additional interventions.","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"_prob = remake(prob, tspan = (0.0, 6 * 7.0))\nprob_violating_threshold(_prob, [u_conv => Uniform(0.0, 1.0)], [accumulation_I > 0.4 * NN]) # TODO: explain 0.4*NN","category":"page"},{"location":"scenarios/scenario3/#Question-3","page":"Scenario 3: Limiting Deaths","title":"Question 3","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"We are interested in determining how effective it would be to institute a mandatory mask mandate for the duration of the next six weeks. What is the probability of staying below 6000 cumulative deaths if we institute an indefinite mask mandate starting May 1, 2020?","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"_prob = remake(_prob, p = [u_expo => 0.02])\nprob_violating_threshold(_prob, [u_conv => Uniform(0.0, 1.0)], [accumulation_I > 0.4 * NN])","category":"page"},{"location":"scenarios/scenario3/#Question-4","page":"Scenario 3: Limiting Deaths","title":"Question 4","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"We are interested in determining how detection rate can affect the accuracy and uncertainty in our forecasts. In particular, suppose we can improve the baseline detection rate by 20%, and the detection rate stays constant throughout the duration of the forecast. Assuming no additional interventions (ignoring Question 3), does that increase the amount of cumulative forecasted cases and deaths after six weeks? How does an increase in the detection rate affect the uncertainty in our estimates? Can you characterize the relationship between detection rate and our forecasts and their uncertainties, and comment on whether improving detection rates would provide decision-makers with better information (i.e., more accurate forecasts and/or narrower prediction intervals)?","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"# these new equations add I->D and H->R  to the model.\n# this says now, that all I are undetected and u_hosp is the detection rate.\n# this assumes there is always hospital capacity\neqs2 = [Differential(t)(S) ~ -(u_expo / N) * I * S\n    Differential(t)(E) ~ (u_expo / N) * I * S - (u_conv / N) * E\n    Differential(t)(I) ~ (u_conv / N) * E - (u_hosp / N) * I - (u_rec / N) * I -\n                         (u_death / N) * I\n    Differential(t)(R) ~ (u_rec / N) * I + (u_rec / N) * H\n    Differential(t)(H) ~ (u_hosp / N) * I - (u_death / N) * H - (u_rec / N) * H\n    Differential(t)(D) ~ (u_death / N) * H + (u_death / N) * I]\n@named seirhd_detect = ODESystem(eqs2)\nsys2 = add_accumulations(seirhd_detect, [I])\nu0init2 = [\n    S => 0.9 * NN,\n    E => 0.05 * NN,\n    I => 0.01 * NN,\n    R => 0.02 * NN,\n    H => 0.01 * NN,\n    D => 0.01 * NN,\n]\nsys2_ = structural_simplify(sys2)\n@unpack accumulation_I = sys2_\n\nprobd = ODEProblem(sys2_, u0init2, (0.0, tend))\nsold = solve(probd; saveat = ts)\nplot(sold)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"sols = []\nu_detects = 0:0.1:1\nfor x in u_detects\n    probd = remake(probd, p = [u_hosp => x])\n    sold = solve(probd; saveat = sold.t)\n    push!(sols, sold)\nend\n\n# demonstrate that the total infected count is strictly decreasing with increasing detection rate\nis = map(x -> x[accumulation_I][end], sols)\nplot(is)\n@test issorted(is; rev = true)\n\n# deaths decrease with increasing detection rate\nds = map(x -> x[D][end], sols)\nplot(ds)\n@test issorted(ds; rev = true)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"get_uncertainty_forecast(_prob, accumulation_I, 0:100,\n    [u_hosp => Uniform(0.0, 1.0), u_conv => Uniform(0.0, 1.0)],\n    6 * 7)\n\nplot_uncertainty_forecast(probd, accumulation_I, 0:100,\n    [\n        u_hosp => Uniform(0.0, 1.0),\n        u_conv => Uniform(0.0, 1.0),\n    ],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Compute the accuracy of the forecast assuming no mask mandate (ignoring Question 3) in the same way as you did in Question 1 and determine if improving the detection rate improves forecast accuracy.","category":"page"},{"location":"scenarios/scenario3/#Question-5","page":"Scenario 3: Limiting Deaths","title":"Question 5","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Convert the MechBayes SEIRHD model to an SIRHD model by removing the E compartment. Compute the same six-week forecast that you had done in Question 1a and compare the accuracy of the six-week forecasts with the forecasts done in Question 1a.","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"prob2 = prob\nget_uncertainty_forecast(prob2, [accumulation_I], 0:100, [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast(prob2, [accumulation_I], 0:100, [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"get_uncertainty_forecast_quantiles(prob2, [accumulation_I], 0:100,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast_quantiles(prob2, [accumulation_I], 0:100,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Further modify the MechBayes SEIRHD model and do a model space exploration and model selection from the following models, based on comparing forecasts of cases and deaths to actual data: SEIRD, SEIRHD, and SIRHD models. Use data from April 1, 2020 – April 30, 2020 from the scenario location (Massachusetts) for fitting these models.  Then make out-of-sample forecasts from the same 6-week period from May 1 – June 15, 2020, and compare with actual data. Comment on the quality of the fit for each of these models.","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"prob3 = prob\nget_uncertainty_forecast(prob2, [accumulation_I], 0:100, [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast(prob2, [accumulation_I], 0:100, [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"get_uncertainty_forecast_quantiles(prob2, [accumulation_I], 0:100,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"plot_uncertainty_forecast_quantiles(prob2, [accumulation_I], 0:100,\n    [u_conv => Uniform(0.0, 1.0)],\n    6 * 7)","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"Do a 3-way structural model comparison between the SEIRD, SEIRHD, and SIRHD models.","category":"page"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"#","category":"page"},{"location":"scenarios/scenario3/#https://github.com/SciML/EasyModelAnalysis.jl/issues/22","page":"Scenario 3: Limiting Deaths","title":"https://github.com/SciML/EasyModelAnalysis.jl/issues/22","text":"","category":"section"},{"location":"scenarios/scenario3/#Question-7","page":"Scenario 3: Limiting Deaths","title":"Question 7","text":"","category":"section"},{"location":"scenarios/scenario3/","page":"Scenario 3: Limiting Deaths","title":"Scenario 3: Limiting Deaths","text":"What is the latest date we can impose a mandatory mask mandate over the next six weeks to ensure, with 90% probability, that cumulative deaths do not exceed 6000? Can you characterize the following relationship: for every day that we delay implementing a mask mandate, we expect cumulative deaths (over the six-week timeframe) to go up by X?","category":"page"},{"location":"scenarios/scenario1/#Scenario-1:-Vaccination","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"","category":"section"},{"location":"scenarios/scenario1/#Generate-the-Model-and-Dataset","page":"Scenario 1: Vaccination","title":"Generate the Model and Dataset","text":"","category":"section"},{"location":"scenarios/scenario1/#Setup","page":"Scenario 1: Vaccination","title":"Setup","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"using Catlab, Catlab.CategoricalAlgebra, Catlab.Programs, Catlab.WiringDiagrams, Catlab.Graphics\nusing AlgebraicPetri\nusing AlgebraicPetri.BilayerNetworks\nusing AlgebraicDynamics.UWDDynam\nusing LabelledArrays\nusing OrdinaryDiffEq, DelayDiffEq\nusing Plots\n\nusing ASKEM.Dec2022Demo: formSIRD, formInfType, augLabelledPetriNet, sirdAugStates, typeSIRD,\n  makeMultiAge, typeAge, typed_stratify, formVax, vaxAugStates, typeVax, writeMdlStrat,\n  loadSVIIvR, sviivrAugStates, typeSVIIvR\nusing ASKEM.SubACSets: mca\nusing ASKEM.Stratify: stratify_typed\n\ntypes′ = LabelledPetriNet([:Pop],\n  :infect => ((:Pop, :Pop) => (:Pop, :Pop)),\n  :disease => (:Pop => :Pop),\n  :strata => (:Pop => :Pop),\n  :natural => (:Pop => :Pop),\n  )\ntypes = map(types′, Name=name -> nothing)\n\n# Parts of type system for ease of reference\ns, = parts(types′, :S)\nt_interact, t_disease, t_strata,t_natural  = parts(types′, :T)\ni_interact1, i_interact2, i_disease, i_strata, i_natural = parts(types′, :I)\no_interact1, o_interact2, o_disease, o_strata, o_natural = parts(types′, :O);","category":"page"},{"location":"scenarios/scenario1/#Original-SEIRD-model-from-the-paper","page":"Scenario 1: Vaccination","title":"Original SEIRD model from the paper","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"seirdnat = LabelledPetriNet([:S, :E, :I, :R, :D],\n  :inf => ((:S, :I) => (:E, :I)),\n  :conv => (:E => :I),\n  :rec => (:I => :R),\n  :death => (:I => :D),\n  :nat_d_s => (:S => ()),\n  :nat_d_e => (:E => ()),\n  :nat_d_i => (:I => ()),\n  :nat_d_r => (:R => ()),\n  :nat_birth => (() => :S),\n)\n\n# seirdnat_aug = augLabelledPetriNet(seirdnat, [:S, :E, :I, :R])\nseirdnat_typed = ACSetTransformation(seirdnat, types,\n  S=[s, s, s, s, s],\n  T=[t_interact, t_disease, t_disease, t_disease, t_disease, t_disease, t_disease, t_disease, t_natural],\n  I=[i_interact1, i_interact2, i_disease, i_disease, i_disease, i_disease, i_disease, i_disease, i_disease],\n  O=[o_interact1, o_interact2, o_disease, o_disease, o_disease, o_natural],\n  Name=name -> nothing\n)\n@assert is_natural(seirdnat_typed)","category":"page"},{"location":"scenarios/scenario1/#Model-of-vaccination-process","page":"Scenario 1: Vaccination","title":"Model of vaccination process","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"vax_lpn = LabelledPetriNet([:U, :V],\n  :infuu => ((:U, :U) => (:U, :U)),\n  :infvu => ((:V, :U) => (:V, :U)),\n  :infuv => ((:U, :V) => (:U, :V)),\n  :infvv => ((:V, :V) => (:V, :V)),\n  :vax => (:U => :V),\n)\n\nVax_aug_typed = ACSetTransformation(vax_lpn, types,\n  S=[s, s],\n  T=[t_interact, t_interact, t_interact, t_interact, t_strata],\n  I=[i_interact1, i_interact2, i_interact1, i_interact2, i_interact1, i_interact2, i_interact1, i_interact2, i_strata],\n  O=[o_interact1, o_interact2, o_interact1, o_interact2, o_interact1, o_interact2, o_interact1, o_interact2, o_strata],\n  Name=name -> nothing\n)\n@assert is_natural(Vax_aug_typed)","category":"page"},{"location":"scenarios/scenario1/#Original-model-stratified-with-vaccination","page":"Scenario 1: Vaccination","title":"Original model stratified with vaccination","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"seirdnat_vax = stratify_typed(\n  seirdnat_typed=>[[:strata],[:strata],[:strata],[:strata],[]],\n  Vax_aug_typed=>[[:disease,:natural],[:disease,]],\n  types′)","category":"page"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"conv: exposed => infected","category":"page"},{"location":"scenarios/scenario1/#Model-3.a.i-for-comparison","page":"Scenario 1: Vaccination","title":"Model 3.a.i for comparison","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"# SEIRDnat \"stratified with vax\"\nfunction formSEIRDnatV()\n  SEIRDnatV = LabelledPetriNet([:Sv, :Ev, :Iv, :Rv, :D],\n    :inf => ((:Sv, :Iv) => (:Ev, :Iv)),\n    :conv => (:Ev => :Iv),\n    :rec => (:Iv => :Rv),\n    :death => (:Iv => :D),\n    :nat_d_s => (:Sv => ()),\n    :nat_d_e => (:Ev => ()),\n    :nat_d_i => (:Iv => ()),\n    :nat_d_r => (:Rv => ()),\n  )\n  return SEIRDnatV\nend\n\nseirdnat_v = formSEIRDnatV()","category":"page"},{"location":"scenarios/scenario1/#Model-3.a.ii-for-comparison","page":"Scenario 1: Vaccination","title":"Model 3.a.ii for comparison","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"# CHIMESVIIvR\nsviivr_lbn_pth = joinpath(@__DIR__, \"CHIME_SVIIvR_dynamics_BiLayer.json\")\nsviivr_lbn = read_json_acset(LabelledBilayerNetwork, sviivr_lbn_pth)\nsviivr = LabelledPetriNet()\nmigrate!(sviivr, sviivr_lbn)","category":"page"},{"location":"scenarios/scenario1/#Model-Analysis","page":"Scenario 1: Vaccination","title":"Model Analysis","text":"","category":"section"},{"location":"scenarios/scenario1/#Question-3-Numerical-Comparison","page":"Scenario 1: Vaccination","title":"Question 3 Numerical Comparison","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"Compare simulation outputs between the three models, for the following two scenarios. Assume initial values and parameter values are consistent (to the extent possible) with Table 1 in https://biomedres.us/pdfs/BJSTR.MS.ID.007413.pdf. For initial values that are not specified, choose reasonable values and ensure they are the same between the three models being compared. i.\tVaccine efficacy = 75%, population vaccinated = 10% ii.\tVaccine efficacy = 75%, population vaccinated = 80%","category":"page"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"E(0) = 99500      # exposed I(0) = 1          # infected recovered, deceased = 0 N = 10000000 mu = 0.012048     # death rate alpha = 0.00142   # fatality rate among unvaccinated alphav = 0.00142 # fatality rate among vaccinated betauu = 0.75    # probability of transmission per unvax contact * # of unvax contacts per time gamma^-1 = 3.31   # reciprocal of recovery rate of unvax gammav^-1 = 3.31 # \" vax eps^-1 = 5.7      # reciprocal of rate of exposed,unvax => infectious,unvax epsv^-1 = 5.79   # \" vax xi = 0.5          # vaccine efficacy kappa             # fraction vaccinated","category":"page"},{"location":"scenarios/scenario1/#Run-model-3ai","page":"Scenario 1: Vaccination","title":"Run model 3ai","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"system = ODESystem(seirdnat_v) prob = ODEProblem(system, [10000000-99500, 99500, 1, 0, 0.0], [0, 100], [0.75, 1/5.7, 1/3.31, 0.012048, 1e-3, 1e-3, 1e-3, 1e-3])","category":"page"},{"location":"scenarios/scenario1/#Question-4","page":"Scenario 1: Vaccination","title":"Question 4","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"Create an equally weighted ensemble model using the three models in 3b, and replicate the scenarios in 3.c.i and 3.c.ii. How does the ensemble model output compare to the output from the individual component models?","category":"page"},{"location":"scenarios/scenario1/#Question-5","page":"Scenario 1: Vaccination","title":"Question 5","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"For any of the models in question 3, conduct a sensitivity analysis to determine which intervention parameters should be prioritized in the model, for having the greatest impact on deaths – NPIs, or vaccine-related interventions?","category":"page"},{"location":"scenarios/scenario1/#Question-6","page":"Scenario 1: Vaccination","title":"Question 6","text":"","category":"section"},{"location":"scenarios/scenario1/","page":"Scenario 1: Vaccination","title":"Scenario 1: Vaccination","text":"With the age-stratified model, simulate the following situations. You may choose initial values that seem reasonable given the location and time, and you can reuse values from any of the publications referenced): i.\tHigh vaccination rate among older populations 65 years and older (e.g. 80%+), and low vaccination rate among all other age groups (e.g. below 15%) ii.\tHigh vaccination rate among all age groups iii.\tRepeat d.i and d.ii, but now add a social distancing policy at schools, that decreases contact rates by 20% for school-aged children only. iv.\tCompare and summarize simulation outputs for d.i-d.iii","category":"page"},{"location":"scenarios/scenario5/#Scenario-5:-Bucky-model","page":"Scenario 5: Bucky model","title":"Scenario 5: Bucky model","text":"","category":"section"},{"location":"scenarios/scenario5/","page":"Scenario 5: Bucky model","title":"Scenario 5: Bucky model","text":"The original Bucky model is structured to handle population data stratified in 16 5-year bins, as described in the documentation. You’ve recently found a publication about an age-structured SIR model describing the spread of Covid in the state of Washington, USA, which was ‘ground zero’ of the Covid-19 pandemic in the United States, with the first confirmed case and first confirmed death in the country. (https://doi.org/10.1038/s41598-021-94609-3). Modify the Bucky model to use data stratified in 9 10-year bins, as shown in the age-contact matrix in Figure 1. Simulate the first 3 months of the Covid-19 pandemic in Washington, using the modified Bucky model.","category":"page"},{"location":"api/data_fitting_calibration/#Data-Fitting-and-Model-Calibration","page":"Data Fitting and Model Calibration","title":"Data Fitting and Model Calibration","text":"","category":"section"},{"location":"api/data_fitting_calibration/","page":"Data Fitting and Model Calibration","title":"Data Fitting and Model Calibration","text":"datafit\nglobal_datafit\nbayesian_datafit","category":"page"},{"location":"api/data_fitting_calibration/#EasyModelAnalysis.datafit","page":"Data Fitting and Model Calibration","title":"EasyModelAnalysis.datafit","text":"datafit(prob, p, t, data)\ndatafit(prob, p, data)\n\nFit parameters p to data measured at times t.\n\nArguments\n\nprob: ODEProblem\np: Vector of pairs of symbolic parameters and initial guesses for the parameters.\nt: Vector of time-points\ndata: Vector of pairs of symbolic states and measurements of these states at times t.\n\nKeyword Arguments\n\n- `loss`: the loss function used for fitting. Defaults to `EasyModelAnalysis.l2loss`,\n  with an alternative being `EasyModelAnalysis.relative_l2loss` for relative weighted error.\n\np does not have to contain all the parameters required to solve prob, it can be a subset of parameters. Other parameters necessary to solve prob default to the parameter values found in prob.p. Similarly, not all states must be measured.\n\nData Definition\n\nThe data definition is given as a vctor of pairs. If t is specified globally for the datafit, then those time series correspond to the time points specified. For example, \n\n[\nx => [11.352378507900013, 11.818374125301172, -10.72999081810307]\nz => [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545]\n]\n\nthen if datafit(prob, p, t, data), t must be length 3 and these values correspond to x(t[i]).\n\nIf datafit(prob, p, data), then the data must be a tuple of (t, timeseries), for example:\n\n[\nx => ([1.0, 2.0, 3.0], [11.352378507900013, 11.818374125301172, -10.72999081810307])\nz => ([0.5, 1.5, 2.5, 3.5], [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545])\n]\n\nwhere this means x(2.0) == 11.81...\n\n\n\n\n\n","category":"function"},{"location":"api/data_fitting_calibration/#EasyModelAnalysis.global_datafit","page":"Data Fitting and Model Calibration","title":"EasyModelAnalysis.global_datafit","text":"global_datafit(prob, pbounds, t, data; maxiters = 10000)\nglobal_datafit(prob, pbounds, data; maxiters = 10000)\n\nFit parameters p to data measured at times t.\n\nArguments\n\nprob: ODEProblem\npbounds: Vector of pairs of symbolic parameters to vectors of lower and upper bounds for the parameters.\nt: Vector of time-points\ndata: Vector of pairs of symbolic states and measurements of these states at times t.\n\nKeyword Arguments\n\nmaxiters: how long to run the optimization for. Defaults to 10000. Larger values are slower but more robust.\nloss: the loss function used for fitting. Defaults to EasyModelAnalysis.l2loss, with an alternative being EasyModelAnalysis.relative_l2loss for relative weighted error.\n\np does not have to contain all the parameters required to solve prob, it can be a subset of parameters. Other parameters necessary to solve prob default to the parameter values found in prob.p. Similarly, not all states must be measured.\n\nData Definition\n\nThe data definition is given as a vctor of pairs. If t is specified globally for the datafit, then those time series correspond to the time points specified. For example, \n\n[\nx => [11.352378507900013, 11.818374125301172, -10.72999081810307]\nz => [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545]\n]\n\nthen if datafit(prob, p, t, data), t must be length 3 and these values correspond to x(t[i]).\n\nIf datafit(prob, p, data), then the data must be a tuple of (t, timeseries), for example:\n\n[\nx => ([1.0, 2.0, 3.0], [11.352378507900013, 11.818374125301172, -10.72999081810307])\nz => ([0.5, 1.5, 2.5, 3.5], [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545])\n]\n\nwhere this means x(2.0) == 11.81...\n\n\n\n\n\n","category":"function"},{"location":"api/data_fitting_calibration/#EasyModelAnalysis.bayesian_datafit","page":"Data Fitting and Model Calibration","title":"EasyModelAnalysis.bayesian_datafit","text":"bayesian_datafit(prob, p, t, data)\nbayesian_datafit(prob, p, data)\n\nCalculate posterior distribution for parameters p given data measured at times t.\n\nData Definition\n\nThe data definition is given as a vctor of pairs. If t is specified globally for the datafit, then those time series correspond to the time points specified. For example, \n\n[\nx => [11.352378507900013, 11.818374125301172, -10.72999081810307]\nz => [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545]\n]\n\nthen if datafit(prob, p, t, data), t must be length 3 and these values correspond to x(t[i]).\n\nIf datafit(prob, p, data), then the data must be a tuple of (t, timeseries), for example:\n\n[\nx => ([1.0, 2.0, 3.0], [11.352378507900013, 11.818374125301172, -10.72999081810307])\nz => ([0.5, 1.5, 2.5, 3.5], [2.005502877055581, 13.626953144513832, 5.382984515620634, 12.232084518374545])\n]\n\nwhere this means x(2.0) == 11.81...\n\n\n\n\n\n","category":"function"},{"location":"examples/ASIR/#Analysis-of-The-Asymptomatic-SIR-Model","page":"Analysis of The Asymptomatic SIR Model","title":"Analysis of The Asymptomatic SIR Model","text":"","category":"section"},{"location":"examples/ASIR/","page":"Analysis of The Asymptomatic SIR Model","title":"Analysis of The Asymptomatic SIR Model","text":"First, we implement the asymptomatic SIR model from BioMedInformatics 2022, 2(3), 398-404; https://doi.org/10.3390/biomedinformatics2030025.","category":"page"},{"location":"examples/ASIR/","page":"Analysis of The Asymptomatic SIR Model","title":"Analysis of The Asymptomatic SIR Model","text":"using EasyModelAnalysis\n@variables t\nDₜ = Differential(t)\n@variables S(t)=0.9 Iₐ(t)=0.05 Iₛ(t)=0.01 Rₐ(t)=0.2 Rₛ(t)=0.1 D(t)=0.01\n@parameters α=0.6 βₐ=0.143 βₛ=0.055 ρ=0.003 μₙ=0.007 μₘ=0.011 θ=0.1 ωₛ=0.14\neqs = [Dₜ(S) ~ μₙ * S - μₘ * S - θ * α * S * Iₛ - (1 - θ) * α * S * Iₐ + ρ * (Rₐ + Rₛ)\n    Dₜ(Iₐ) ~ (1 - θ) * α * S * Iₐ - βₐ * Iₐ\n    Dₜ(Iₛ) ~ θ * α * S * Iₛ - βₛ * Iₛ\n    Dₜ(Rₐ) ~ βₐ * Iₐ - ρ * Rₐ\n    Dₜ(Rₛ) ~ (1 - ωₛ) * βₛ * Iₛ - ρ * Rₛ\n    Dₜ(D) ~ ωₛ * βₛ * Iₛ]\n@named asir = ODESystem(eqs)\nprob = ODEProblem(asir, [], (0, 110.0))\nsol = solve(prob)\nplot(sol)","category":"page"},{"location":"getting_started/#Getting-Started-with-EasyModelAnalysis","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"EasyModelAnalysis.jl is made to work with a ModelingToolkit.jl model. If one is unfamiliar with ModelingToolkit, check out its tutorial before getting started. We will start by defining our model as the ModelingToolkit's README example:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"using EasyModelAnalysis, Plots\n\n@parameters t σ ρ β\n@variables x(t) y(t) z(t)\nD = Differential(t)\n\neqs = [D(D(x)) ~ σ * (y - x),\n    D(y) ~ x * (ρ - z) - y,\n    D(z) ~ x * y - β * z]\n\n@named sys = ODESystem(eqs)\nsys = structural_simplify(sys)\n\nu0 = [D(x) => 2.0,\n    x => 1.0,\n    y => 0.0,\n    z => 0.0]\n\np = [σ => 28.0,\n    ρ => 10.0,\n    β => 8 / 3]\n\ntspan = (0.0, 100.0)\nprob = ODEProblem(sys, u0, tspan, p, jac = true)\nsol = solve(prob)","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"EasyModelAnalysis.jl then makes it easy to do complex queries about the model with simple one-line commands. For example, let's evaluate the values of x at times [0.0, 1.0, 2.0]:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"get_timeseries(prob, x, [0.0, 1.0, 2.0])","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"That's too simple, so now let's grab the time points where x achieves its maximum and minimum:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"xmin, xminval = get_min_t(prob, x)","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"xmax, xmaxval = get_max_t(prob, x)","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"Was that simple? Let's see what x looks like:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"phaseplot_extrema(prob, x, (x, y))","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"plot_extrema(prob, x)","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"and boom, it grabbed the correct value in something that's relatively difficult. That's the core of EasyModelAnalysis!","category":"page"},{"location":"getting_started/#Lazily-Defining-Observables","page":"Getting Started with EasyModelAnalysis","title":"Lazily Defining Observables","text":"","category":"section"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"One thing to note about EasyModelAnalysis is that algebraically defined observables can be used in place of any state definition. As an example, let's say we wished to get the time series points for abs(x+y)^2. To do that, we would just make that be our observable:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"get_timeseries(prob, abs(x + y)^2, [0.0, 1.0, 2.0])","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"and similarly for extrema:","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"xmin, xminval = get_min_t(prob, abs(x + y)^2)","category":"page"},{"location":"getting_started/","page":"Getting Started with EasyModelAnalysis","title":"Getting Started with EasyModelAnalysis","text":"This applies to data fitting, sensitivity analysis, thresholds, and everything!","category":"page"},{"location":"tutorials/threshold_interventions/#Designing-Threshold-Interventions","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"","category":"section"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"In this tutorial, we will demonstrate how to analyze “threshold interventions”, i.e., how to do calculations of model results to determine quantities around thresholds and the interventions to fix/avoid thresholds. Thresholds are meant to answer queries like “what is the first time point where the number of COVID cases will cross 10% of the population?”, or “when will the ball reach the wall?”. Intervention is then an assessment of policies around such thresholds. For example, “when should we start and stop an enforced masking policy to keep the total number of COVID cases below 10% for the full-time period?”. Thus, these two analyses go hand in hand: threshold queries give us information about when thresholds will be reached, while intervention functions give us optimal strategies for avoiding such thresholds.","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"To see this in action, let's create a model of the population of rabbits in a post-apocalyptic Earth where fauna and humans have moved to Mars on SpaceX ships, but a few bunnies were accidentally left behind to use Earth as an approximately infinite food source. As you may recall from this model in elementary ecology courses, this is best defined by a linear ODE system, which we define in the ModelingToolkit sense:","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"using EasyModelAnalysis\n@variables t 🐰(t)\n@parameters p\nD = Differential(t)\neqs = [D(🐰) ~ p * 🐰]\n@named sys = ODESystem(eqs)\nprob = ODEProblem(sys, [🐰 => 0.01], (0.0, 10.0), [p => 1.0])","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"In this model x(t) is the number of billions of bunnies (commonly referred to in the units bB) and t is given in units of months. Solving this ODE shows the number of bunnies grows exponentially over time as they are all fat and happy with plenty of grass to feed on:","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"plot(solve(prob))","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"We can ask, how long does it take for this exponential growth to cause the continuous number of bunnies x to cross the value of 50bB? Let's ask:","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"get_threshold(prob, 🐰, 50)","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"Which, eyeballing the plot, looks correct: in about 8 and half months the population will reach 50 billion bunnies!","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"But now let's create an intervention. Let's say a corporation has created an “Earth viewing tourism” business where humans are watching the bunny population through a telescope. Market research has found that when there are more than 3bB in the population, the reaction goes from “that's cute” to “eww too many rodents”, and thus to maximize their profits the corporation wants to fire a laser that indiscriminately kills bunnies at an exponential rate (which just happens to be the same rate as twice the growth of the bunny population). But as you probably know from experience, operating death rays that cover the distance from Mars to Earth cost a lot to operate, so the corporation wants to run this for as short as possible. The company knows they will get shut down after 50 months anyway once regulators catch up, so they only need to keep the planet looking cute for that short amount of time.","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"How should the bunny murder operation commence in order to successfully maximize corporate profits? To get the desired result, we use the optimal_threshold_intervention function. Our intervention will be to decrease the growth rate p = 10 to p = -10 (i.e. decrease it by twice the birth rate). What we want to know is what is the minimal time intervention to keep the population under 3bB until a time 50. Thus, the call looks as follows:","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"opt_tspan, (s1, s2, s3), ret = optimal_threshold_intervention(prob, [p => -1.0], 🐰, 3, 50);\n\nopt_tspan","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"The opt_tspan gives us the optimal timespan of the intervention: we should begin the decimation of bunny civilization when it reaches 5.15 months, and then we can turn the destruction device off at 27.8 months into our tourism operation. To see the effect of this, we can plot the results of the three sub-intervals:","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"plot(s1, lab = \"pre-intervention\")\nplot!(s2, lab = \"intervention\")\nplot!(s3, xlims = (0, s3.t[end]), ylims = (0, 5), lab = \"post-intervention\", dpi = 300)","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"Let's understand this result. Because of the exponential growth, we want to start the laser as late as possible as that will give us the most “bang for the buck”, or rather, “burn for the buck”, killing the most bunnies in the least amount of time. Thus, we want to wait for the population to grow a bit and be easier for the laser to hit. Then we leave the laser on for as short of a time as possible. By choosing 27.8 months as the off point, this will allow for the rest of the time to be tourism friendly. When regulators finally get in touch on the 50th month, the population will have exactly reached the 3bB tipping point, allowing us to fully use that entire time for unburned bunny tourism while also making regulators more sympathetic to our burning cause by the time they reach out to us.","category":"page"},{"location":"tutorials/threshold_interventions/","page":"Designing Threshold Interventions","title":"Designing Threshold Interventions","text":"Of course, this could also be used to uncover optimal policies for handling pandemics, but whatever your desired use case is, churn away.","category":"page"},{"location":"#EasyModelAnalysis.jl","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl","text":"","category":"section"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"EasyModelAnalysis does exactly what it says: it makes model analysis easy. Want to know the first time the number of infected individuals is about 1000? What is the probability that more than 50 people will be infected given probability distributions for the parameters? What variables are the most sensitive? Please find the parameters that best fit the model to the data. All of these, and more, given as simple one-liner queries over ModelingToolkit-defined differential equation models.","category":"page"},{"location":"#Installation","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"Installation","text":"","category":"section"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"To install EasyModelAnalysis.jl, use the Julia package manager:","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"using Pkg\nPkg.add(\"EasyModelAnalysis\")","category":"page"},{"location":"#Contributing","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"Contributing","text":"","category":"section"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"Please refer to the SciML ColPrac: Contributor's Guide on Collaborative Practices for Community Packages for guidance on PRs, issues, and other matters relating to contributing to SciML.\nSee the SciML Style Guide for common coding practices and other style decisions.\nThere are a few community forums:\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Slack\nThe #diffeq-bridged and #sciml-bridged channels in the Julia Zulip\nOn the Julia Discourse forums\nSee also SciML Community page","category":"page"},{"location":"#Reproducibility","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"Reproducibility","text":"","category":"section"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"<details><summary>The documentation of this SciML package was built using these direct dependencies,</summary>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"using Pkg # hide\nPkg.status() # hide","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"</details>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"<details><summary>and using this machine and Julia version.</summary>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"using InteractiveUtils # hide\nversioninfo() # hide","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"</details>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"<details><summary>A more complete overview of all dependencies and their versions is also provided.</summary>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"using Pkg # hide\nPkg.status(; mode = PKGMODE_MANIFEST) # hide","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"</details>","category":"page"},{"location":"","page":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","title":"EasyModelAnalysis.jl: Quick and Easy Queries to Simulation Results","text":"using TOML\nusing Markdown\nversion = TOML.parse(read(\"../../Project.toml\", String))[\"version\"]\nname = TOML.parse(read(\"../../Project.toml\", String))[\"name\"]\nlink_manifest = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n                \"/assets/Manifest.toml\"\nlink_project = \"https://github.com/SciML/\" * name * \".jl/tree/gh-pages/v\" * version *\n               \"/assets/Project.toml\"\nMarkdown.parse(\"\"\"You can also download the\n[manifest]($link_manifest)\nfile and the\n[project]($link_project)\nfile.\n\"\"\")","category":"page"},{"location":"tutorials/probabilistic_thresholds/#Analysis-of-Threshold-Crossing-Probabilities-Under-Uncertainty","page":"Analysis of Threshold Crossing Probabilities Under Uncertainty","title":"Analysis of Threshold Crossing Probabilities Under Uncertainty","text":"","category":"section"},{"location":"examples/petri/#AlgebraicPetri-Integration","page":"AlgebraicPetri Integration","title":"AlgebraicPetri Integration","text":"","category":"section"},{"location":"examples/petri/","page":"AlgebraicPetri Integration","title":"AlgebraicPetri Integration","text":"First, let's load all the libraries and define the simple SIR model in AlgebraicPetri.jl.","category":"page"},{"location":"examples/petri/","page":"AlgebraicPetri Integration","title":"AlgebraicPetri Integration","text":"using EasyModelAnalysis\nusing UnPack\nusing AlgebraicPetri\nusing AlgebraicPetri.Epidemiology\nusing AlgebraicPetri.BilayerNetworks\n\nusing Catlab\nusing Catlab.CategoricalAlgebra\nimport Catlab.CategoricalAlgebra: migrate!\nusing Catlab.WiringDiagrams\nusing Catlab.Programs.RelationalPrograms\n\n# Define SIR Model\nsir = @relation (s, i, r) begin\n    infection(s, i)\n    recovery(i, r)\nend\n\n# Convert to Epidemiology petri net\npsir = apex(oapply_epi(sir))\n\n# Create empty bilayer network\nbnsir = LabelledBilayerNetwork()\n# migrate petri model to bilayer network\nmigrate!(bnsir, psir)","category":"page"},{"location":"examples/petri/","page":"AlgebraicPetri Integration","title":"AlgebraicPetri Integration","text":"Then, we can use ODESystem to convert the Petri net to an ODESystem and all the analysis functionalities would follow naturally.","category":"page"},{"location":"examples/petri/","page":"AlgebraicPetri Integration","title":"AlgebraicPetri Integration","text":"sys = ODESystem(bnsir)\n@unpack S, I, R, inf, rec = sys\nprob = ODEProblem(sys, [S => 0.9, I => 0.1, R => 0.0], (0, 10.0), [inf => 7.0, rec => 1.0])\nsol = solve(prob)\ntmax, imax = get_max_t(prob, I)\nplt = plot(sol)\nscatter!(plt, [tmax], [imax], lab = \"Maximum infection\", leg = :topright)","category":"page"}]
}
